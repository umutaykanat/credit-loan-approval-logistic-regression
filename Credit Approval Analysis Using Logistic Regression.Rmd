
---
title: "Bank Marketing Data Analysis"
author: "Umut Aykanat"
output:
  html_document:
    css: stil.css
    toc: true
    toc_depth: '3'
    df_print: paged
  word_document:
    toc: true
    toc_depth: 3
    number_sections: true
  pdf_document:
    toc: true
    toc_depth: '3'
geometry: a4paper
lang: tr
---

# GÄ°RÄ°Å

Bu proje, Portekizâ€™de bir bankanÄ±n doÄŸrudan pazarlama kampanyalarÄ± sÄ±rasÄ±nda toplanan mÃ¼ÅŸteri verilerini analiz etmeyi amaÃ§lamaktadÄ±r. Veri seti, mÃ¼ÅŸterilerin demografik Ã¶zellikleri (yaÅŸ, medeni durum, eÄŸitim dÃ¼zeyi), finansal durumlarÄ± (bakiye, kredi geÃ§miÅŸi, konut ve kiÅŸisel kredi durumu) ve banka ile iletiÅŸim bilgilerini iÃ§ermektedir. 

Projenin temel hedefi, mÃ¼ÅŸterilerin **vadeli mevduat (term deposit)** teklifini kabul edip etmemelerini etkileyen faktÃ¶rleri incelemektir. BÃ¶ylece pazarlama kampanyalarÄ±nÄ±n baÅŸarÄ±sÄ±nÄ± artÄ±rabilecek deÄŸiÅŸkenler belirlenebilir.

Veri setinde toplam 17 deÄŸiÅŸken bulunmaktadÄ±r. Bunlardan 16â€™sÄ± aÃ§Ä±klayÄ±cÄ± (baÄŸÄ±msÄ±z) deÄŸiÅŸken, biri ise hedef (baÄŸÄ±mlÄ±) deÄŸiÅŸkendir:  
- **BaÄŸÄ±mlÄ± deÄŸiÅŸken:** `y` â€“ MÃ¼ÅŸteri vadeli mevduat teklifini kabul etti mi? (â€œyesâ€ veya â€œnoâ€)  
- **BaÄŸÄ±msÄ±z deÄŸiÅŸkenler:** yaÅŸ, meslek, eÄŸitim durumu, kredi durumu, iletiÅŸim tipi, kampanya sÃ¼resi vb.

Bu analiz kapsamÄ±nda;
- DeÄŸiÅŸkenlerin yapÄ±sÄ± incelenmiÅŸ,  
- Kategorik deÄŸiÅŸkenler gÃ¶rselleÅŸtirilmiÅŸ,  
- Temel Ã¶zet istatistikler sunulmuÅŸ,  

SonuÃ§ olarak proje, pazarlama stratejilerinin daha veriye dayalÄ± ve hedef odaklÄ± hale gelmesine katkÄ± saÄŸlayabilecek iÃ§gÃ¶rÃ¼ler sunmaktadÄ±r.

```{r}
data <- read.csv("/Users/umutaykanat/Desktop/portfolio/banking data/train.csv", sep = ";", header = TRUE)
head(data)
```
# Veri Seti HakkÄ±nda Betimleyici Bilgiler
```{r}
str(data)
```

Verimiz 45211 gÃ¶zlem ve 17 deÄŸiÅŸkenden oluÅŸuyor. DeÄŸiÅŸkenleri tanÄ±yalÄ±m:
**age**: MÃ¼ÅŸterinin yaÅŸÄ±
**job**: Ä°ÅŸ tÃ¼rÃ¼
**marital**: Medeni durumu
**education**: EÄŸitim dÃ¼zeyi
**default**: Kredi temerrÃ¼t durumu
**balance**: Ortalama yÄ±llÄ±k bakiye(â‚¬)
**housing**: Konut kredisi durumu
**loan**: KiÅŸisel kredi durumu
**contact**: Ä°letiÅŸim TÃ¼rÃ¼
**day**: AyÄ±n son iletiÅŸim gÃ¼nÃ¼
**month**: Son iletiÅŸim ayÄ±
**duration**: Son iletiÅŸim sÃ¼resi
**campaign**: Kampanya sÃ¼resince yapÄ±lan iletiÅŸim sayÄ±sÄ±)
**pdays**: Ã–nceki kampanyadan sonra geÃ§en gÃ¼n sayÄ±sÄ±
**previous**: Bu kampanyadan Ã¶nce yapÄ±lan iletiÅŸim sayÄ±sÄ±
**poutcome**: Ã–nceki pazarlama kampanyasÄ±nÄ±n sonucu
**y**: MÃ¼ÅŸteri vadeli mevduata abone oldu mu?

## Veri Tipi DÃ¶nÃ¼ÅŸÃ¼mÃ¼
Kategorik deÄŸiÅŸkenleri factor olarak belirleyelim 
```{r}
# TÃ¼m karakter tipindeki deÄŸiÅŸkenleri faktÃ¶re Ã§evir
data[sapply(data, is.character)] <- lapply(data[sapply(data, is.character)], as.factor)
str(data)
```


## KeÅŸifÃ§i Veri Analizi ve GÃ¶rselleÅŸtirme

Ã–ncelikle hedef deÄŸiÅŸkenin daÄŸÄ±lÄ±mÄ±na bakalÄ±m
```{r}
library(ggplot2)
# Y deÄŸiÅŸkeninin oranlarÄ±nÄ± tablo haline getirelim
y_data <- as.data.frame(table(data$y))
colnames(y_data) <- c("y", "count")
# Pasta grafiÄŸi
ggplot(y_data, aes(x = "", y = count, fill = y)) +
  geom_col(width = 1, color = "white") +
  coord_polar(theta = "y") +
  labs(title = "MÃ¼ÅŸteri Mevduat Kabul OranÄ± (y deÄŸiÅŸkeni)",
       fill = "Mevduat Durumu") +
  theme_void() +
  geom_text(aes(label = paste0(round(count / sum(count) * 100, 1), "%")),
            position = position_stack(vjust = 0.5),
            color = "white",
            size = 5)
```
Vadeli mevduata abone olma durumunun tÃ¼m mÃ¼ÅŸteriler bazÄ±nda daÄŸÄ±lÄ±mÄ± %11.7 evet iken %88.3 hayÄ±rdÄ±r. Hedef deÄŸiÅŸkenin daÄŸÄ±lÄ±mÄ±nda eÅŸitsizlik olduÄŸu gÃ¶z Ã¶nÃ¼nde bulundurulmalÄ±dÄ±r.

Her deÄŸiÅŸkenin alt kategorilerine ait mÃ¼ÅŸteri mevduat kabul oranlarÄ±nÄ± inceleyelim. Bu oranlar tekil incelendiÄŸinde anlamlÄ±dÄ±r. Ã–rneÄŸin kiÅŸinin yalnÄ±zca medeni durumuna gÃ¶re analiz yapÄ±lÄ±rsa mevduata abone olma durumu %6.1 iken olmama durumu %54.1'dir.

DeÄŸiÅŸkenlerin kategorilerinin kendi aralarÄ±nda mÃ¼ÅŸteri mevduat kabul oranlarÄ±nÄ± inceleyelim:
```{r}
library(dplyr)
library(ggplot2)
library(forcats)
library(rlang)

cat_vars <- names(data)[sapply(data, is.factor)]
custom_colors <- c("no" = "#ff6b6b", "yes" = "#1dd1a1")

for (var in cat_vars) {
  p_data <- data %>%
    group_by(across(all_of(var)), y) %>%      # kategori ve y'ye gÃ¶re say
    summarise(count = n(), .groups = "drop") %>%
    group_by(across(all_of(var))) %>%         # kategori bazÄ±nda topla
    mutate(percent = count / sum(count) * 100) %>%
    ungroup()
  
  # label sÃ¼tunu (% formatÄ±nda)
  p_data <- p_data %>% mutate(label = sprintf("%.1f%%", percent))
  
  p <- ggplot(p_data, aes(x = fct_reorder(as.factor(!!sym(var)), percent, .fun = max),
                          y = percent, fill = y, label = label)) +
    geom_col(position = position_dodge(width = 0.9), width = 0.7) +
    geom_text(position = position_dodge(width = 0.9),
              vjust = -0.25, size = 3.5, color = "black") +
    coord_flip() +
    scale_fill_manual(values = custom_colors) +
    labs(title = paste("Term Deposit DaÄŸÄ±lÄ±mÄ± -", var),
         x = var, y = "YÃ¼zde (%)", fill = "Term Deposit") +
    theme_minimal(base_size = 13) +
    theme(plot.title = element_text(face = "bold", hjust = 0.5),
          legend.position = "bottom")
  
  print(p)
}

```

KayÄ±p gÃ¶zlem kontrolÃ¼:
```{r}
sum(is.na(data)) # kayÄ±p gÃ¶zlem gÃ¶rÃ¼nmÃ¼yor.
```

Bu aÅŸamada y deÄŸiÅŸkenini tahmin etmek Ã¼zere regresyon modeli kurup tahmin yapacaÄŸÄ±z

BaÄŸÄ±mlÄ± deÄŸiÅŸkenin daÄŸÄ±lÄ±mÄ±:
```{r}
table(data$y) 
```
BaÄŸÄ±mlÄ± deÄŸiÅŸkenimizin alt kategorilerini incelediÄŸimizde ret sayÄ±sÄ±nÄ±n kabul sayÄ±sÄ±ndan yaklaÅŸÄ±k 7.5 kat fazla olduÄŸu gÃ¶rÃ¼lmektedir. Tahmin modelini eÄŸitirken bu dengesizliÄŸin yaratacaÄŸÄ± yanlÄ±lÄ±ÄŸÄ±n Ã¶nÃ¼ne geÃ§mek adÄ±na eÄŸitim kÃ¼mesine eÅŸit sayÄ±da kabul ve ret iÃ§eren gÃ¶zlemleri dahil etmek gerekmektedir. Bu iÅŸlem yalnÄ±zca eÄŸitim kÃ¼mesinde gerÃ§ekleÅŸtirilecek ve test kÃ¼mesine mÃ¼dahale edilmeyecektir.  

EÄŸitim setine yeterli sayÄ±da kabul ve ret alabilmek adÄ±na dÃ¼zenlemeler yapalÄ±m:

```{r}
library(dplyr)
dataYes <- data %>% filter(y == "yes")
dataNo <- data %>% filter(y == "no")
nrow(dataYes) ; nrow(dataNo)

set.seed(111)
dataNoIndex <- sample(1:nrow(dataNo), size = 0.8*nrow(dataYes))
set.seed(111)
dataYesIndex <- sample(1:nrow(dataYes), size = 0.8*nrow(dataYes))

trainYes <- dataYes[dataYesIndex, ] 
trainNo <- dataNo[dataNoIndex, ]

# Åimdi rbind kullanarak alt gruplardan ayrÄ± ayrÄ± aldÄ±ÄŸÄ±mÄ±z Ã¶rneklemleri satÄ±r bazÄ±nda birleÅŸtirelim. 
trainset<-rbind(trainYes,trainNo)
table(trainset$y) # eÅŸit sayÄ±da no ve yes iÃ§eren gÃ¶zlemi train sete dahil etmiÅŸ olduk.
```

AynÄ± iÅŸlemleri test seti iÃ§in de yapalÄ±m
```{r}
testYes <- dataYes[-dataYesIndex,]
testNo <-dataNo[-dataNoIndex,]

testset<-rbind(testYes, testNo) 
table(testset$y)
```

GLMNET yÃ¶ntemi ile ilk modeli kuralÄ±m
```{r}
library(glmnet)
model_glm <- glm(y ~. , family = "binomial", data = trainset)
summary(model_glm)
```
Ã‡Ä±ktÄ±da modelin anlamlÄ± (p-value < alpha) olduÄŸu gÃ¶rÃ¼nmektedir. NullDeviance(BoÅŸ modelin sapmasÄ±) = 11730.8 elde edilirken, modele deÄŸiÅŸkenler eklendiÄŸinde ResidualDeviance(ArtÄ±klarÄ±n sapmasÄ±) = 6686.7 olarak daha iyi bir model elde edilmiÅŸtir. Yani **baÄŸÄ±msÄ±z deÄŸiÅŸkenlerin eklenmesi modeli iyileÅŸtirmiÅŸtir.** 
Her bir deÄŸiÅŸkenin modele katkÄ±larÄ±nÄ± ve deÄŸiÅŸkenlerin anlamlÄ± olup olmadÄ±klarÄ±nÄ± basitÃ§e Ã§Ä±ktÄ±daki * sayÄ±sÄ±ndan yorumlayabiliriz.  
Modele katkÄ±sÄ± olmayan veya katkÄ±sÄ± az olan deÄŸiÅŸkenlerin model Ã§Ä±karÄ±lmasÄ± model karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± dÃ¼ÅŸÃ¼rmek adÄ±na fayda saÄŸlayacaktÄ±r. Ä°lerleyen aÅŸamalarda bu iÅŸlemlere yer verilecektir.  
Elde edilen model katsayÄ±larÄ± hakkÄ±nda daha detaylÄ± yorumlar yapabilmek adÄ±na exp(ğ›½) katsayÄ±larÄ± elde edilmelidir.
```{r}
exp(coef(model_glm)) 
```
Bu deÄŸerler odds oranÄ±dÄ±r. KatsayÄ± 1â€™in altÄ±ndaysa azaltÄ±cÄ±, 1â€™e eÅŸitse etkisi aynÄ±(fark yok), 1â€™den fazlaysa etkisi fazladÄ±r yorumu yapÄ±labilir.


Pseudo_r2 deÄŸeri:
```{r}
library(pscl)   
pseudo_r2 = pscl::pR2(model_glm)["McFadden"]
pseudo_r2
```
0.40'tan bÃ¼yÃ¼k Pseudo_r2 deÄŸeri modelin anlamlÄ± tahminler yaptÄ±ÄŸÄ±nÄ± iÅŸaret eder. KurduÄŸumuz model anlamlÄ± tahminler yapabilimiÅŸtir!

# Hangi deÄŸiÅŸken modele daha fazla katkÄ± saÄŸlamÄ±ÅŸ?
Bu yorumu yapabilmek iÃ§in Resid. Dev kÄ±smÄ±ndaki deÄŸeri en Ã§ok hangi deÄŸiÅŸkenlerin dÃ¼ÅŸÃ¼rdÃ¼ÄŸÃ¼ incelenir.

```{r}
anova(model_glm)
```

DeÄŸerler incelendiÄŸinde modelin summaryâ€™sinde de olduÄŸu gibi anlamlÄ± Ã§Ä±kan deÄŸiÅŸkenlerin modele katkÄ±sÄ±nÄ±n daha yÃ¼ksek olduÄŸunu gÃ¶rÃ¼yoruz. TÃ¼m deÄŸiÅŸkenler incelendiÄŸinde complexityâ€™ide azaltmak iÃ§in etkisi az olan deÄŸiÅŸkenleri modelden Ã§Ä±karabiliriz. Modelin karmaÅŸÄ±klÄ±ktan uzak olmasÄ± istediÄŸimiz bir ÅŸeydir.

# Model Tahminleri
```{r}
predict1<-predict(model_glm,testset,type="response")
head(predict1)
```


```{r}
library(devtools)
cm<-InformationValue::confusionMatrix(testset$y, predictedScores = predict1)
cm
```
SÃ¼tun isimlerinde yer alan No ve Yes deÄŸerleri test setinde yer alan gerÃ§ek deÄŸerleri, satÄ±r isimlerinde yer alan **0** deÄŸeri model tahmininde **No** olarak belirlenen tahminleri, **1** deÄŸeri ise **Yes** olarak belirlenen tahminleri ifade etmektedir.  
*confusion matrix* incelendiÄŸinde **model_glm** doÄŸru negatifleri(30238 tahmin) tespit etmekte oldukÃ§a baÅŸarÄ±lÄ± gÃ¶rÃ¼nÃ¼yor. BaÅŸka bir deyiÅŸle model_glm mevduata abone olmama durumunu doÄŸru tahmin etmekte baÅŸarÄ±lÄ± ancak mevduata abone olma durumunu doÄŸru tahmin etmekte iyileÅŸtirmeler yapÄ±labilir. Bu deÄŸerlendirmeleri **accuracy(doÄŸruluk) ve errorrate(hata oranÄ±)** metriklerinde de inceleyelim:

**Accuracy** toplam gÃ¶zlem sayÄ±sÄ±snÄ±n doÄŸru atamalara oranlanmasÄ± ile edle edilen bir metricdir.

```{r}
accuracy1<-(cm[2,2]+cm[1,1])/sum(cm)
accuracy1
```
**accuracy** metriÄŸi doÄŸru tahminlerin tÃ¼m tahminlere oranlamasÄ±yla elde edillir. Tahminlerde %84 doÄŸruluk oranÄ± saÄŸlanmÄ±ÅŸ olmasÄ±na karÅŸÄ±n yanlÄ±ÅŸ negatiflerin Ã§ok olmasÄ± durumu iyileÅŸtirilebilir.

Bir de **Error Rate**(hata oranÄ±na) bakalÄ±m. Hata oranÄ± yanlÄ±ÅŸ atamalarÄ±n toplam gÃ¶zlem sayÄ±sÄ±na oranlanmasÄ±yla elde edilir.
```{r}
errorRate1<-(cm[1,2]+cm[2,1])/sum(cm)
errorRate1
```
Hata oranÄ± %15 olarak elde edildi. Yani model1 ile bir tahminde bulunulduÄŸunda %85 doÄŸru %15 yanlÄ±ÅŸ bir sonuÃ§ elde edilecektir.

# GLM MODEL Ä°YÄ°LEÅTÄ°RMESÄ°

## Optimal Cut_off Value

```{r}
# install.packages("InformationValue")
library(InformationValue)

optCutoff<-InformationValue::optimalCutoff(testset$y,predictedScores=predict1)
optCutoff 
```
Esik degeri cok kucuk bulunmustur 0.0099 Burda **optCutt_off** point belirlenirken dikkate alÄ±nan metric 
*accurcy* dir. Fakat probleme gÃ¶re veriye gÃ¶re bu durum deÄŸiÅŸiklik gÃ¶sterebilir. 
Yani accuracyâ€™ye gÃ¶re **cutoff_point** belirlememiz bazen yanÄ±ltÄ±cÄ± olabilir.
Testte iyi sonuÃ§lar verirken gerÃ§ek hayat probleminde elde edilen cutoff_pointe gÃ¶re sonuÃ§lar 
gerÃ§eÄŸi yansÄ±tmayabilir. Ve cutoff-point'in belirlenmesi bazen araÅŸtÄ±rÄ±cÄ±ya da bÄ±rakÄ±labilir.  
Åimdi bu optimal cutoff noktasÄ±na gÃ¶re confusion matrixi yeniden oluÅŸturursak;
```{r}
cmOpt<-InformationValue::confusionMatrix(testset$y,predictedScores = predict1,
                                         threshold =optCutoff )
cmOpt       # threshold deÄŸerini optcutoff yaptÄ±k.
```
```{r}
accuracyopt<-(cmOpt[2,2]+cmOpt[1,1])/sum(cmOpt)
accuracyopt; cm; cmOpt
```
Bu noktada cutoff_pointe gore atandÄ±gÄ±nda **positive-positive** oranÄ± artmÄ±ÅŸ fakat **negative-negative** oranÄ± dÃ¼ÅŸmÃ¼ÅŸtÃ¼r. Accuracy deÄŸerinin de dÃ¼ÅŸtÃ¼ÄŸÃ¼ gÃ¶rÃ¼lmektedir.
Bu noktada amaca gore doÄŸru eÅŸik deÄŸeri belirlenmelidir. AraÅŸtÄ±rma bazÄ±nda hangi metriÄŸin kritik rol aldÄ±ÄŸÄ±na baÄŸlÄ± olarak cutt_off deÄŸeri ayarlanabilir. Ã–rneÄŸin doÄŸru-pozitifleri yakalamanÄ±n Ã¶nemli olduÄŸu hastalÄ±k teÅŸhisi gibi durumlar olabilir.
Bu durum test verisi uzerindende inceleme yaparak karar verilebilir.





















Daha Ã¶nce belirtildiÄŸi gibi yanlÄ±ÅŸ negatiflerin(Tip I hata) sebebini inceleyelim:
```{r}
summary(predict1)
```
**model_glm** kullanÄ±larak elde edilen tahminlerin medyan deÄŸeri 0.16 gibi dÃ¼ÅŸÃ¼k bir deÄŸer gelmiÅŸtir. Default(varsayÄ±lan) olarak 0.5 odds oranÄ± ile Ã§alÄ±ÅŸtÄ±ÄŸÄ±mÄ±z iÃ§in bu sonuÃ§ ortaya Ã§Ä±kmÄ±ÅŸ olabilir. Optimal cut_off value belirleyerek bu konuda iyileÅŸtirme yapÄ±labilir. Ä°lerleyen aÅŸamalarda bu konuya deÄŸinilecektir.

# Ä°KÄ°NCÄ° MODELÄ°N KURULMASI
Daha az baÄŸÄ±msÄ±z deÄŸiÅŸkenle daha iyi bir model kurmak pek Ã§ok aÃ§Ä±dan avantajlÄ± bir durumdur. Daha basit bir model kurmak adÄ±na deÄŸiÅŸken sayÄ±sÄ± azaltÄ±labilir. AnlamlÄ± deÄŸiÅŸkenlerle modeli tekrar kurup daha iyi bir model elde etmeye Ã§alÄ±ÅŸalÄ±m:



```{r}
new_train_set <- trainset %>% select(job,marital,education,default,balance,housing,loan,contact,day,month,duration,campaign,pdays,previous,poutcome,y)
head(new_train_set)
```

```{r}
model_glm2 <- glm(y ~.,
              family = "binomial", data = new_train_set) 
summary(model_glm2)
```

```{r}
pseudo_r2 = pscl::pR2(model_glm)["McFadden"]
pseudo_r2_2 = pscl::pR2(model_glm2)["McFadden"]
pseudo_r2 ; pseudo_r2_2

```

```{r}
predict2 <- predict(model_glm2, testset ,type="response")
head(predict2)
```

# Accuracy
```{r}
cm2 <- InformationValue::confusionMatrix(testset$y, predictedScores = predict2)
cm2
accuracy2  <-(cm2[2,2]+cm2[1,1])/sum(cm2)
accuracy2
```

# Recall
```{r}
recall2<-(cm2[2,2])/(cm2[1,2]+cm2[2,2])
recall2
```
Recall deÄŸeri 0.8043478 bulunmuÅŸtur. Modelin pozitif Ã¶rneklerin %80.43478â€™ini doÄŸru bir ÅŸekilde tespit ettiÄŸi anlamÄ±na gelir.

# Precision
Kesinlik (Precision) Positive olarak tahminlediÄŸimiz deÄŸerlerin gerÃ§ekten kaÃ§ adedinin Positive olduÄŸunu gÃ¶stermektedir.


```{r}
precision2 <- (cm2[2,2])/(cm2[2,1]+cm2[2,2])
precision2
```
Yani model *mÃ¼ÅŸteri vadeli mevduat aboneliÄŸi kabul olanlarÄ±* %13.50794 kesinlikle tahmin edebiliyor ÅŸeklinde yorumlanabilir.

# Sensivity
Sensivity(DuyarlÄ±lÄ±k) aslÄ±nda Recall ile aynÄ± fÃ¶rmÃ¼lÃ¼zasyona sahiptir.

```{r}
sensivity2<-(cm2[2,2])/(cm2[1,2]+cm2[2,2])
sensivity2
```
Positive classlarÄ± tahmin ederken ne kadar hassaslÄ±kla tahminde bulunuluÄŸunu gÃ¶sterir. model2â€™nin confusion matrixâ€™i iÃ§in bu deÄŸeri %80.43478 olarak elde edildi.

# Specifity
Negative classÄ± ne kadar iyi tahmin edebildiÄŸimizi gÃ¶steren bir metriktir. Bu durumda *mevduata abone olmama durumunu* tahmin etmedeki model baÅŸarÄ±sÄ±nÄ± gÃ¶sterecektir.
```{r}
specificity2<-(cm2[1,1])/(cm2[2,1]+cm2[1,1])
specificity2
```
Accuracy deÄŸeriyle yakÄ±n bir deÄŸer(0.8473285) elde ettik. Metrikler Ã¼zerindeki gÃ¶zlemlerimiz sonucunda modelimizin **doÄŸru negatifleri bulmada** baÅŸarÄ±lÄ± bir model olduÄŸunu gÃ¶rebiliyoruz.

# F1 Scoru
F1â€™in yÃ¼ksek olmasÄ± positive classlarÄ±n tahmininde modelin iyi olduÄŸunu belirten bir Ã¶lÃ§Ã¼t olarak kullanÄ±labilir. Bizim modelimiz iÃ§in iyi sonuÃ§ vermesini beklemeyiz.
```{r}
f1_score2<-2*((precision2*recall2)/(precision2+recall2))
f1_score2
```
Modelin mevduata abone olma durumunu tahmin etme F1 scoru %23 olarak elde edilmistir. Bir kez daha modelin *mevduata abone olmama durumunu* tahmin etmede baÅŸarÄ±lÄ± olduÄŸunu vurgulayabiliriz.

# ROC CURVE
EÄŸrinin altÄ±nda kalan alan anlamÄ±nÄ± taÅŸÄ±maktadÄ±r. Alan bÃ¼yÃ¼klÃ¼ÄŸÃ¼ 0-1 arasÄ±ndadÄ±r ve 1â€™e yakÄ±n deÄŸerler tercih edilir. Yani eÄŸri altÄ±nda kalan alan bÃ¼yÃ¼dÃ¼kÃ§e model iyileÅŸir.
```{r}
#install.packages("pROC")
library(pROC)
rocModel2<-roc(testset$y~predict2)
plot(rocModel2)

```

YukarÄ±daki gÃ¶rselde eÄŸri altÄ±nda kalan alanÄ± gÃ¶zlemleyebiliriz. Bir de sayÄ±sal deÄŸer olarak bakalÄ±m:
```{r}
rocModel2
```
Area under the curve(eÄŸri altÄ±nda kalan alan) %90.5 olarak elde edilmiÅŸtir ve gayet iyi bir sonuÃ§tur.

# SonuÃ§: Elde Edilen Tahmin Denklemi ve YorumlanmasÄ±

Ä°lk olarak 1. model(model_glm) veri setine uygun olarak *binomial logistic regresyon* kullanÄ±larak elde edilmiÅŸ ve katsayÄ±larÄ± yorumlanmÄ±ÅŸtÄ±r. Daha sonrasÄ±nda 2. model(model_glm_2) elde edilirken complexityâ€™i dÃ¼ÅŸÃ¼rmek hedeflenerek anlamsÄ±z deÄŸiÅŸkenler modelden Ã§Ä±kartÄ±lmÄ±ÅŸ ve confusionmatrix Ã¼zerinden metriklerle karÅŸÄ±laÅŸtÄ±rma yapÄ±lÄ±p model yorumlanmÄ±ÅŸtÄ±r. SeÃ§ilen model(model_glm_2)â€™yi iyileÅŸtirmek iÃ§in cut_off value belirlenmesi gibi Ã§eÅŸitli yollara gidilmiÅŸ ve uygun adÄ±mlar uygulanmÄ±ÅŸtÄ±r.


```{r}
library(dplyr)

data <- data %>%
  mutate(age_group = cut(
    age,
    breaks = c(18, 25, 35, 45, 55, 65, 100),
    labels = c("18-25", "26-35", "36-45", "46-55", "56-65", "65+"),
    right = FALSE
  ))

```

```{r}
summary_data <- data %>% 
  group_by(age_group) %>%
  summarise(yas_bazinda_onay_orani = mean(y=="yes"), 
            yas_bazinda_ortalama_butce = mean(balance))
```

```{r}
library(ggplot2)
ggplot(summary_data, aes(x = age_group, y = yas_bazinda_onay_orani)) +
  geom_col() +
  labs(
    title = "YaÅŸ AralÄ±klarÄ±na GÃ¶re Onay OranÄ±",
    x = "YaÅŸ AralÄ±ÄŸÄ±",
    y = "Onay OranÄ±"
  ) +
  theme_minimal()
```

```{r}
ggplot(summary_data, aes(x = age_group, y = yas_bazinda_ortalama_butce)) +
  geom_col() +
  labs(
    title = "YaÅŸ AralÄ±klarÄ±na GÃ¶re Ortalama Limit",
    x = "YaÅŸ AralÄ±ÄŸÄ±",
    y = "Ortalama BÃ¼tÃ§e"
  ) +
  theme_minimal()
```

Bu iki grafikten anlaÅŸÄ±lacaÄŸÄ± Ã¼zre ortalama bÃ¼tÃ§e deÄŸiÅŸkeni onay oranÄ± Ã¼zerinde kesin bir etkiye sahip deÄŸildir. YaÅŸ aralÄ±ÄŸÄ± arttÄ±kÃ§a ortalama bÃ¼tÃ§e artmasÄ±na raÄŸmen onay oranlarÄ± orta yaÅŸ gruplarÄ±nda dÃ¼ÅŸÃ¼k yÃ¼zdelerde seyir etmektedir.


## DeÄŸiÅŸkenler ArasÄ±ndaki Korelasyon KatsayÄ±larÄ±
```{r}
str(data)

num_vars = names(data)[sapply(data, is.numeric)]

cor_mat <- cor(data[num_vars])


cor_list <- as.data.frame(as.table(cor_mat))

cor_list <- cor_list %>%
  dplyr::filter(Var1 != Var2) %>%
  dplyr::distinct() 

cor_sorted <- cor_list %>%
  dplyr::arrange(desc(Freq))

head(cor_sorted)
```


## Modelin Test Seti Tahminleri
Bu adÄ±mda modelden, modele daha Ã¶nce gÃ¶stermediÄŸimiz test seti gÃ¶zlemlerini tahmin etmesini isteyeceÄŸiz. Model kurulurken modeli eÄŸitmek iÃ§in eÄŸitim-test seti olarak bÃ¶lmÃ¼ÅŸtÃ¼k. Buradaki test set modelin hiÃ§ gÃ¶rmediÄŸi deÄŸerlerden oluÅŸmaktadÄ±r. KarÄ±ÅŸtÄ±rÄ±lmamalÄ±dÄ±r.
```{r}
test_data <- read.csv("/Users/umutaykanat/Desktop/portfolio/banking data/test.csv", sep = ";", header = TRUE)
head(test_data)
```


```{r}
predict_test <- predict(model_glm,test_data,type="response")
head(predict_test)
```

```{r}
library(devtools)
cm<-InformationValue::confusionMatrix(test_data$y, predictedScores = predict_test)
cm
```

```{r}
accuracy_test<-(cm[2,2]+cm[1,1])/sum(cm)
accuracy_test
```

Test setine iliÅŸkin tahminlerin accuray oranÄ± **%83.7'dir.** Modelin test set Ã¼zerinde baÅŸarÄ±lÄ± tahminler yaptÄ±ÄŸÄ±nÄ± sÃ¶yleyebiliriz.


### TEÅEKKÃœRLER
**Umut Aykanat**
